---
title: "filter_load"
author: "Georg"
date: "5/11/2022"
output: html_document
---

```{r, message=FALSE}
library(devtools)
#install_github('legendenomgeorg/VitalDBR/VitalDBR')
library(VitalDBR)
library("tidyverse")
library(readr)
library(mgcv)
library(profvis)
library(data.table)
library(RcppRoll)
library(RcppArmadillo)
#library(sandwich)
```
Det er åbenbart meget udfordrende at lave en funktion der kan tage en liste af argumenter, og så passe dem ind i filter funktionen, så det blir bare lige sådan her fremadrettet. Det hører nok også under basic r
```{r}
cases <- VitalDBR::load_VDB("https://api.vitaldb.net/cases") %>%
      dplyr::filter(approach=="Open",
                department=="General surgery",
                ane_type=="General") %>%
      dplyr::select(caseid, death_inhosp, icu_days, age, sex, asa, emop, bmi, opstart, opend)
cases

# slet death in hosp
```

Har fjernet den dårlige version
# better version


Nå 3 min efter gik jeg havde sagt tak for i aften gik det op for mig at jeg kunne have gjort det meget mere simpelt. 
- Find alle caseid's der lever op til de der conditions ligesom ovenfor
- importer tracks med VitalDBR::load_VDB("https://api.vitaldb.net/cases")
- Find alle caseid's der har både Primus/AWP og SNUADC/ART. Og join de to tables. Så har man alle de case id'er vi skal finde
```{r}
tracks <- VitalDBR::load_VDB("https://api.vitaldb.net/trks") %>%
    dplyr::filter(tname == "Primus/AWP" | tname == "SNUADC/ART") %>%
    count(caseid) %>%
    dplyr::filter(n == 2)

```

```{r}
merged <- merge(x=tracks,y=cases,by="caseid") %>% dplyr::select(-one_of("n"))
#merged %>% dplyr::filter(death_inhosp==1)
#merged %>% dplyr::filter(icu_days>10)
```


```{r}
merged
```
Pas på med at fjerne NA, fordi så forsvinder nogle af de operationer hvor de døde!

```{r}
max(merged$icu_days)+1
table(merged$icu_days)
hist(merged$icu_days, breaks=82)
```


```{r}
#profvis({
find_abp_beats <- function(data,
                           abp_col = 2,
                           time_col = 1,
                           min_PP = 0.20,
                           min_beat_width_s = 0.3,
                           win_size_avg = 2000,
                           show.plot = FALSE,
                           include_waveform = FALSE,
                           sample_rate = NULL) {

    assertthat::not_empty(data)


    if (is.vector(data)) {

        abp <- data
    } else {
        abp <- data[[abp_col]]
        time_vector <- data[[time_col]]
    }

    if(is.na(abp[1])) {
        return(NA)
    }

    min_beat_width <- as.integer(min_beat_width_s * sample_rate)

    #create cuttoff pressure from average pressure (RcppRoll::roll_mean is fast)
    moving_mean_p <- RcppRoll::roll_mean(
        #repeat avg of last measurements (* movingavg_win) to get equal lengths
        c(abp,rep(mean(tail(abp, win_size_avg)), win_size_avg-1)),
        n = win_size_avg)

    # group cycles
    # finds every crossing of cutoff pressure, and keeps only changes from high to low
    # abp < cutoff gives a series of T/F:  TTTTFFFFTTTTFFFFTT
    # diff find only changes (+ = +1):     000-000+000-000+00
    # == 1 keeps only +1 change:           000000010000000100
    # (cumsum creates groups:               000000011111111222)
    cross_index <- which(c(diff(abp < (moving_mean_p * 1.1)), 0) == 1)

    cross_groups <- waveformtools::splitAt(abp, cross_index, trim_ends = FALSE)

    # Split abp by diastoles
    dia_index <- purrr::map_int(cross_groups, which.min) + c(0, cross_index - 1)

    # Check that no beats are shorter than mean beat width.
    while (any(diff(dia_index) < min_beat_width)) {
        short_i <- which(diff(dia_index) < min_beat_width)[1]

        # If a shorter interval is found. Keep the index with the lowest abp (the true diastole)
        # If the shorter index is the last, just remove it.
        if (short_i == length(dia_index) || abp[dia_index[short_i+1]] < abp[dia_index[short_i]]) {
            dia_index <- dia_index[-short_i]
        }
        else dia_index <- dia_index[-(short_i + 1)]

    }

    beat_groups <- waveformtools::splitAt(abp, dia_index, trim_ends = FALSE) # Do not trim, since the start is needed for timing.

    res <- dplyr::tibble(beat_wave = beat_groups)
    res <- dplyr::mutate(res,
                         dia = purrr::map_dbl(beat_wave, ~.x[1]),
                         sys = purrr::map_dbl(beat_wave, ~max(.x)),
                         which.sys = purrr::map_int(beat_wave, ~which.max(.x)),
                         segment_len = purrr::map_int(beat_wave, ~length(.x)),
                         dia_pos = dplyr::lag(cumsum(segment_len), default = 1),
                         sys_pos = which.sys + dia_pos - 1, # Both are 1 indexed, so to make the global position 1 indexed subtract 1
                         PP = sys - dia)

    if(!is.null(sample_rate)) res$segment_len <- res$segment_len * 1/sample_rate

    res <- dplyr::filter(res,
                         dia_pos > 20, # First min cannot be among the first 20 samples
                         dia_pos < length(abp) - 100) # and last min cannot be among the last 60
                                                     # (to avoid detecting a dicrotic notch as a diastole)


    # Detect Noise
    pos_after_sys <- function(x) {
        if (is.null(sample_rate)) return(NA)

        diff_x <- diff(x)

        slopes <- rle(diff_x > 0)

        # Three positive slopes are accepted
        # (systole (+ deflection) and dichrotic notch)
        pos_slopes <- which(slopes$values == TRUE)

        slopes$values[head(pos_slopes, 3)] <- FALSE

        sum(diff_x[inverse.rle(slopes)]) / (length(diff_x) * (1/sample_rate))
    }

    res <- dplyr::mutate(res,
                         # Wiggliness is calculated similarly to gam smooth funtion wiggliness
                         # Sum of squared 2nd derivative.
                         .noise_wiggliness = purrr::map_dbl(beat_wave, ~sum(diff(diff(.x))^2)),
                         .noise_pos_after_sys = purrr::map_dbl(beat_wave, pos_after_sys))

    if(!include_waveform) {
        res$beat_wave <- NULL
    }

    res <- dplyr::select(res,
                         dia_pos,
                         dia,
                         sys_pos,
                         sys,
                         PP,
                         beat_len = segment_len,
                         contains('.noise'),
                         contains('beat_wave'))

    if (show.plot) {
        plot(abp, type = 'l')
        points(res$dia_pos, res$dia)
        points(res$sys_pos, res$sys)
        lines(moving_mean_p * 1.1, col = 'red')
    }
    if (is.vector(data)) {
        res
    } else {

        res <- dplyr::mutate(res, time = time_vector[dia_pos],
                      time_systole = time_vector[sys_pos])
        dplyr::select(res,
               time,
               dia,
               sys,
               PP,
               beat_len,
               time_systole,
               dplyr::everything())
    }

}

```

```{r}

calc_PPV <- function(smooth, intercept) {
min_PP <- min(smooth)
max_PP <- max(smooth)
(max_PP - min_PP) / unname(intercept)
}

ppv_prepare <- function(case, start, end, data_art, data_awp){
  # det tager usandsynligt lang tid, så vi skal have fixet den load funktion....
  # men ellers er det bare at implemetere PPV udregningen her
  op <- end - start
  interval <- 120
  iterations <- floor(op/interval)
  
  first_deque <- deque()
  last_deque <- deque()
  
  data <- c(matrix(NA, nrow=iterations+2))
  skip_to_next <- FALSE
  
  for (i in 0:iterations){
        try_catch <- tryCatch(
    {
    sub_awp <- VitalDBR::subset_data(data = data_awp, seconds = interval, start_sec = start+(interval*i))
    insp_start <- VitalDBR::get_inspiration_start(sub_awp)
    sub_art <- VitalDBR::subset_data(data = data_art, seconds = interval, start_sec = start+(interval*i), filter=TRUE, cut_freq = 25)
    beats <- find_abp_beats(sub_art, abp_col=3, time_col=1)
    beats_indexed <- waveformtools::add_time_since_event(beats, time_event = insp_start$time)
    rm(beats)
    PP_data <- beats_indexed[,c("PP","time","ann_rel_index")]
    PP_gam <- gam(
    PP ~ 
    s(ann_rel_index,k = 10, bs = "cc" ) + s(time, k = 10, bs = "cr"), # splines
    knots = list(ann_rel_index = c(0,1)), method = "REML", data = PP_data )
    splines <- predict(PP_gam, type = "terms")
    PPV <- calc_PPV(splines[,1], intercept = coef(PP_gam)[1])*100
    data[i] <- PPV
    
    if (length(first_deque) < 15){
      push(first_deque, PPV)
      push(last_deque, PPV)
    }
    if (length(last_deque) > 14){
      popback(last_deque)
      push(last_deque, PPV)
    }
    
    cat("Iteration",i, "out of ", iterations,". For case:",case,"\n")
    rm(PP_data)
    },
    error = function(e){
      skip_to_next <<- TRUE
    }
    )
    if(skip_to_next) { 
      data[i] <- NA
      next 
    }
  }
  
  first30_avg <- 0
  last30_avg <- 0
  for (i in 1:(min(15, length(first_deque)))){
    first30_avg <- first30_avg + pop(first_deque)
    last30_avg <- last30_avg + pop(last_deque)
  }
  
  data[iterations+1] <- first30_avg / min(15, iterations)
  data[iterations+2] <- last30_avg / min(15, iterations)
  
  return(data)
}

process_cases <- function(data){
  ppv_under5 <- data.frame(matrix(NA, nrow = nrow(data)))
  ppv_over8 <- data.frame(matrix(NA, nrow = nrow(data)))
  
  ppv_first30 <- data.frame(matrix(NA, nrow = nrow(data)))
  ppv_last30 <- data.frame(matrix(NA, nrow = nrow(data)))
  
  counter <- 0 
  break_and_save <- FALSE
  for (caseid in data$caseid){
    counter <- counter + 1 
    closeAllConnections()
            try_catch <- tryCatch(
    {
    cat("Importing ART for case:",caseid,"\n")
    art <- VitalDBR::load_case('SNUADC/ART', caseid)
    cat("Importing AWP for case:",caseid,"\n")
    awp <- VitalDBR::load_case('Primus/AWP', caseid)
    },
    error = function(e){
      break_and_save <<- TRUE
      })
            
    if(break_and_save) {
      cat("Something went wrong when loading case:", caseid,"Saving results so far", "\n" )
      break 
      } 
    start <- data$opstart[data$caseid==caseid] # This line and below could be optimized
    end <- data$opend[data$caseid==caseid] # - II -
    ppv_results <- na.omit(ppv_prepare(caseid, start, end, art,awp))
    rm(art)
    rm(awp)
    
    ppv_first30[counter, 1] <- ppv_results[length(ppv_results)-1]
    ppv_last30[counter, 1] <- ppv_results[length(ppv_results)]
    
    # remove first and last 30 mins avg PPV from data vector, only leave PPV's from all 2min iterations
    ppv_results <- ppv_results[0: (length(ppv_results)-2)]
    
    len_ppv <- length(ppv_results)
    ppv_under5[counter, 1] <- sum(ppv_results<=5)/len_ppv
    ppv_over8[counter, 1] <- sum(ppv_results>=8)/len_ppv
    
  }
  colnames(ppv_under5) <- c('ppv_under5')
  colnames(ppv_over8) <- c('ppv_over8')
  data <- cbind(data, ppv_under5)
  data <- cbind(data, ppv_over8)
  colnames(ppv_first30) <- c('ppv_avg_first30')
  colnames(ppv_last30) <- c('ppv_avg_last_30')
  data <- cbind(data, ppv_first30)
  data <- cbind(data, ppv_last30)
  return(data)
} 

#startTime <- Sys.time()
#ppv_data <- process_cases(merged)
#endTime <- Sys.time()
#print(endTime - startTime)
#View(ppv_data)
##})
#path <- getwd()
#filename = paste(path, 'df30.csv',sep = '')
#write.csv(ppv_data, filename)

```

```{r}
process_cases(merged[20:22,])
```



